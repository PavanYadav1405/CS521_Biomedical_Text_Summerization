{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xhnXwCwKOmBA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f1e9f44-2ccc-467b-bd2f-f118c8d0cd4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.15.0-py3-none-any.whl (521 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting pyarrow-hotfix (from datasets)\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.6)\n",
            "Requirement already satisfied: huggingface-hub>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.19.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.3.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.18.0->datasets) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.18.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: pyarrow-hotfix, dill, multiprocess, datasets\n",
            "Successfully installed datasets-2.15.0 dill-0.3.7 multiprocess-0.70.15 pyarrow-hotfix-0.6\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.24.1-py3-none-any.whl (261 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m261.4/261.4 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu118)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.19.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.24.1\n"
          ]
        }
      ],
      "source": [
        "#pip install torch\n",
        "#pip install bert-extractive-summarizer\n",
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install -U accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fnIy_ZUVl54_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0636d38-f355-4596-842e-1cf4af575222"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'sumpubmed'...\n",
            "remote: Enumerating objects: 130808, done.\u001b[K\n",
            "remote: Counting objects: 100% (44/44), done.\u001b[K\n",
            "remote: Compressing objects: 100% (38/38), done.\u001b[K\n",
            "remote: Total 130808 (delta 22), reused 17 (delta 6), pack-reused 130764\u001b[K\n",
            "Receiving objects: 100% (130808/130808), 346.82 MiB | 12.07 MiB/s, done.\n",
            "Resolving deltas: 100% (38368/38368), done.\n",
            "Updating files: 100% (130765/130765), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/vgupta123/sumpubmed.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "czXuAhjymzJi"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from datasets import Dataset\n",
        "import pandas as pd\n",
        "import re\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, GPT2Config\n",
        "from transformers import TextDataset, DataCollatorForLanguageModeling\n",
        "from transformers import Trainer, TrainingArguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "om3Kx8Kfoqvv"
      },
      "outputs": [],
      "source": [
        "def load_text_files(directory):\n",
        "    files = os.listdir(directory)\n",
        "    files = [file for file in files if not file.startswith('.DS')]\n",
        "    files = sorted(files, key=lambda x: int(re.split('\\.|_', x)[1]))\n",
        "    print(len(files))\n",
        "    data = []\n",
        "    for file in files:\n",
        "        if file.endswith('.txt'):\n",
        "            with open(os.path.join(directory, file), 'r', encoding='utf-8',errors='ignore') as f:\n",
        "                text = f.read()\n",
        "                data.append(text)\n",
        "    return data\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print(re.split('\\.|_', 'text_1010.txt'))"
      ],
      "metadata": {
        "id": "zlSN8LGJZ5HB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jSKIvOvBcel",
        "outputId": "dc4ffd37-0666-4cd7-94cd-8b16b0573208"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32689\n",
            "32689\n",
            "32689\n",
            "32689\n"
          ]
        }
      ],
      "source": [
        "# Load text files from directories\n",
        "original_text = load_text_files('/content/sumpubmed/abstract')\n",
        "summaries = load_text_files('/content/sumpubmed/shorter_abstract')\n",
        "# original_text = load_text_files('/content/sumpubmed/text')\n",
        "# summaries = load_text_files('/content/sumpubmed/abstract')\n",
        "print(len(original_text))\n",
        "print(len(summaries))\n",
        "\n",
        "# Create a dataset from the loaded text files\n",
        "data = {'original_text': original_text, 'summary': summaries}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbywV66hB3tM",
        "outputId": "003fd297-a881-4cb3-fc6b-450c6263db71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32689, 2)\n"
          ]
        }
      ],
      "source": [
        "# Create a dataset from the loaded text files\n",
        "df =pd.DataFrame({'original_text': original_text, 'summary': summaries})\n",
        "\n",
        "# dataset = Dataset.from_dict(data)\n",
        "\n",
        "print(df.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "O_3bxNj2CHDo"
      },
      "outputs": [],
      "source": [
        "# Load pre-trained model and tokenizer\n",
        "model_name = \"gpt2\"  # or specify another GPT model suitable for text generation\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "V8_zV3I8CM4r"
      },
      "outputs": [],
      "source": [
        "# Tokenize the dataset\n",
        "# def tokenize_function(ds):\n",
        "#     return tokenizer(ds[\"original_text\"] + \" [SEP] \" + ds[\"summary\"])\n",
        "\n",
        "# tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Save the tokenized dataset to a text file\n",
        "# tokenized_datasets.save_to_disk(\"/content/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "25__SbtmFZfs"
      },
      "outputs": [],
      "source": [
        "df['input_text'] = df[\"original_text\"].iloc[:1000] + \" TL;DR \" + df[\"summary\"].iloc[:1000]\n",
        "df[\"input_text\"].to_csv(\"/content/combined_text.txt\", index=False, header=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "nAKbpSS9JBV9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3178dd64-5a93-44d1-cc17-ec218834695b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32689, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# df['input_text'].iloc[:2]\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJVihfB_GQJR",
        "outputId": "72cd8551-2b0b-4fc2-d73d-fc4974ed94da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ü§ó Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Load your dataset\n",
        "train_file = \"/content/combined_text.txt\"\n",
        "train_dataset = TextDataset(\n",
        "    tokenizer=tokenizer,\n",
        "    file_path=train_file,\n",
        "    block_size=128,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "TFQSPBEcIikN"
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "jvAUXLHCIlBG"
      },
      "outputs": [],
      "source": [
        "# Fine-tuning arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"/content/gpt2-finetuned-summarization\",\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=4,\n",
        "    save_steps=10000,\n",
        "    save_total_limit=2,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "44mKxfInIwtb"
      },
      "outputs": [],
      "source": [
        "# Initialize Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=train_dataset,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 978
        },
        "id": "raIj6sCDI0P0",
        "outputId": "3d19c4af-3081-4356-edb7-c36af352e40a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='13185' max='13185' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [13185/13185 39:46, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>3.638300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>3.470100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>3.401900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>3.359100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>3.313900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>3.300700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>3.261500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>3.254200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>3.239100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>3.216700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>3.229400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>3.201000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>3.192500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>3.162600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>3.173000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>3.161100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>3.139700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>3.137600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>3.134300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>3.122100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10500</td>\n",
              "      <td>3.117600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11000</td>\n",
              "      <td>3.126600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11500</td>\n",
              "      <td>3.089200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12000</td>\n",
              "      <td>3.103000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12500</td>\n",
              "      <td>3.110100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13000</td>\n",
              "      <td>3.108000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/gpt2-finetuned-summarization/tokenizer_config.json',\n",
              " '/content/gpt2-finetuned-summarization/special_tokens_map.json',\n",
              " '/content/gpt2-finetuned-summarization/vocab.json',\n",
              " '/content/gpt2-finetuned-summarization/merges.txt',\n",
              " '/content/gpt2-finetuned-summarization/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "# Fine-tune the model\n",
        "trainer.train()\n",
        "\n",
        "# Save the fine-tuned model\n",
        "model.save_pretrained(\"/content/gpt2-finetuned-summarization\")\n",
        "tokenizer.save_pretrained(\"/content/gpt2-finetuned-summarization\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the fine-tuned model and tokenizer\n",
        "model_path = \"/content/gpt2-finetuned-summarization\"  # Replace with the actual path to your fine-tuned model\n",
        "model = GPT2LMHeadModel.from_pretrained(model_path)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_path)"
      ],
      "metadata": {
        "id": "41fLv63KK_Z8"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = df['original_text'][10000]\n",
        "print(df['original_text'][10000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7QbhffnLLQ5",
        "outputId": "299a7c0f-fc58-4a4d-8e93-836f76dd6acb"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BACKGROUND\n",
            "in mammals, pheromones play an important role in social and innate reproductive behavior within species. in rodents, vomeronasal receptor type  <dig> , which is specifically expressed in the vomeronasal organ, is thought to detect pheromones. the v1r gene repertoire differs dramatically between mammalian species, and the presence of species-specific v1r subfamilies in mouse and rat suggests that v1r plays a profound role in species-specific recognition of pheromones. in ruminants, however, the molecular mechanism for pheromone perception is not well understood. interestingly, goat male pheromone, which can induce out-of-season ovulation in anestrous females, causes the same pheromone response in sheep, and vice versa, suggesting that there may be mechanisms for detecting \"inter-species\" pheromones among ruminant species.\n",
            "\n",
            "\n",
            "RESULTS\n",
            "we isolated  <dig> goat and  <dig> sheep intact v1r genes based on sequence similarity with  <dig> cow v1r genes in the cow genome database. we found that all of the goat and sheep v1r genes have orthologs in their cross-species counterparts among these three ruminant species and that the sequence identity of v1r orthologous pairs among these ruminants is much higher than that of mouse-rat v1r orthologous pairs. furthermore, all goat v1rs examined thus far are expressed not only in the vomeronasal organ but also in the main olfactory epithelium.\n",
            "\n",
            "\n",
            "CONCLUSIONS\n",
            "our results suggest that, compared with rodents, the repertoire of orthologous v1r genes is remarkably conserved among the ruminants cow, sheep and goat. we predict that these orthologous v1rs can detect the same or closely related chemical compound within each orthologous set/pair. furthermore, all identified goat v1rs are expressed in the vomeronasal organ and the main olfactory epithelium, suggesting that v1r-mediated ligand information can be detected and processed by both the main and accessory olfactory systems. the fact that ruminant and rodent v1rs have distinct features suggests that ruminant and rodent v1rs have evolved distinct functions.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the input text\n",
        "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\", max_length=1024, truncation=False)\n",
        "\n",
        "# Generate the summary\n",
        "summary_ids = model.generate(input_ids, max_new_tokens=512 , num_beams=4, length_penalty=2.0, early_stopping=True) #max_length=512\n",
        "\n",
        "# Decode and print the generated summary\n",
        "generated_summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "print(generated_summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnoDL8ChL5KP",
        "outputId": "44a69444-986a-405f-a65e-8e27cc608858"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BACKGROUND\n",
            "in mammals, pheromones play an important role in social and innate reproductive behavior within species. in rodents, vomeronasal receptor type  <dig>, which is specifically expressed in the vomeronasal organ, is thought to detect pheromones. the v1r gene repertoire differs dramatically between mammalian species, and the presence of species-specific v1r subfamilies in mouse and rat suggests that v1r plays a profound role in species-specific recognition of pheromones. in ruminants, however, the molecular mechanism for pheromone perception is not well understood. interestingly, goat male pheromone, which can induce out-of-season ovulation in anestrous females, causes the same pheromone response in sheep, and vice versa, suggesting that there may be mechanisms for detecting \"inter-species\" pheromones among ruminant species.\n",
            "\n",
            "\n",
            "RESULTS\n",
            "we isolated  <dig> goat and  <dig> sheep intact v1r genes based on sequence similarity with  <dig> cow v1r genes in the cow genome database. we found that all of the goat and sheep v1r genes have orthologs in their cross-species counterparts among these three ruminant species and that the sequence identity of v1r orthologous pairs among these ruminants is much higher than that of mouse-rat v1r orthologous pairs. furthermore, all goat v1rs examined thus far are expressed not only in the vomeronasal organ but also in the main olfactory epithelium.\n",
            "\n",
            "\n",
            "CONCLUSIONS\n",
            "our results suggest that, compared with rodents, the repertoire of orthologous v1r genes is remarkably conserved among the ruminants cow, sheep and goat. we predict that these orthologous v1rs can detect the same or closely related chemical compound within each orthologous set/pair. furthermore, all identified goat v1rs are expressed in the vomeronasal organ and the main olfactory epithelium, suggesting that v1r-mediated ligand information can be detected and processed by both the main and accessory olfactory systems. the fact that ruminant and rodent v1rs have distinct features suggests that ruminant and rodent v1rs have evolved distinct functions.\n",
            "\n",
            " TL;DR BACKGROUND\n",
            "in mammals, v <dig> is a member of the v <dig> gene family, which is a member of the v <dig> gene family. v <dig> is a member of the v <dig> gene family. v <dig> is a member of the v <dig> gene family, which is a member of the v <dig> gene family. v <dig> is a member of the v <dig> gene family, which is a member of the v <dig> gene family. v <dig> is a member of the v <dig> gene family, which is a member of the v <dig> gene family, which is a member of the v <dig> gene family. v <dig> is a member of the v <dig> gene family, which is a member of the v <dig> gene family, which is a member of the v <dig> gene family, which is a member of the v <dig> gene family, which is a member of the v <dig> gene family, which is a member of the v <dig> gene family, which is a member of the v <dig> gene family, which is a member of the v <dig> gene family, which is a member of the v <dig> gene family, which is a member of the v <dig> gene family, which is a member of the v <dig> gene family, which is a member of the v <dig> gene family, which is a member of the v <dig> gene family, which is a member of the v <dig> gene family, which is a member of the v <dig> gene family, which is a member of the v <dig> gene family, which is a member of the v <dig> gene family, which is a member of the v <dig> gene family, which is a member of the v <dig> gene family, which is a member of the v <dig> gene family, which is a member of the v <dig> gene family, which is a member of the v <dig> gene family, which is a member of the v <dig> gene family, which is a member of the v <dig> gene family, which is a member of the v <dig> gene family, which is a member of the v <dig> gene family, which is a member of the v <dig> gene family, which is a member\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}